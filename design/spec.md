Below is an implementation-grade **Minimum Lovable Product (MLP) spec** for an **instant + flawless**, **mobile-first** demo app that surfaces **credit quality updates** for TA Realty‚Äôs tenant base with **expert-level relevance filtering** and **zero noise** by default.

---

# 1) Product Scope

## 1.1 Objective

Deliver a **Railway-hosted demo web app** that:

* Automatically surfaces **credit-material tenant events**‚Äîboth negative and positive‚Äî(news + SEC filings + other signals),
* Produces **analyst-quality, structured memos** with citations,
* Provides **portfolio + property + tenant** views for two personas,
* Is **mobile-responsive** and feels **instant** (precomputed/cached).

## 1.2 Non-goals (explicitly out of scope for MLP)

* Valuation modeling
* Underwriting, rent roll analytics, lease abstraction
* Live monitoring during demo (we simulate ‚Äúmonitoring‚Äù via precomputed snapshots)
* Full tenant ingestion UI and data ops tooling (we‚Äôll hardcode/import a demo dataset)

---

# 2) Personas & Core Use Cases

## 2.1 Personas

### Asset Manager (AM) ‚Äî üî¨ Microscope user

* Manages 20‚Äì30 properties, 1‚Äì12+ tenants each
* Asks: **"What do I do next?"**
* Needs: drill-down into specific tenants, actionable memos, evidence
* Entry point: tenant-level issues ‚Üí memo ‚Üí evidence

### Head of Assets / Valuations (Exec) ‚Äî üåç Telescope user

* Oversees entire portfolio, manages AMs
* Asks: **"Where should I worry ‚Äî and why ‚Äî in under 30 seconds?"**
* Needs: synthesized narrative, aggregated risk posture, week-over-week delta
* Entry point: portfolio narrative ‚Üí themes ‚Üí affected entities ‚Üí drill-down

**Key insight:** Same data, different entry points. Execs want opinionated summaries with judgment baked in ‚Äî not tenant lists, tables, or dashboards.

## 2.2 Primary Use Cases (demo must nail)

**Executive (telescope):**
1. **Executive Portfolio Brief:** Synthesized narrative + risk posture + week-over-week delta in <30 seconds
2. **Concentration insights:** Where risk is clustering (not single tenants)
3. **Drill-down on demand:** Tap any insight ‚Üí see supporting entities ‚Üí memo ‚Üí evidence

**Asset Manager (microscope):**
4. **AM Credit Brief:** Top 3‚Äì7 actionable items for assigned properties
5. **One-tap Action Memo:** What changed ‚Üí why it matters ‚Üí what to do ‚Üí evidence
6. **Property view:** Issues for that property + tenant roster with statuses
7. **Tenant timeline:** Sparse, material-only event history with citations

**Shared:**
8. **Search:** Find any tenant/property instantly; resolves entities cleanly
9. **Alert inbox:** A small, curated queue of "needs review"

---

# 2.3) Executive Briefing Layer ‚Äî The Missing Telescope

Executives do **not** want tenant lists, long tables, filters, or dashboards with 12 widgets.

They want **opinionated summaries** ‚Äî the kind humans write in IC memos:

> "Here's what matters this week. Here's what changed. Here's what's getting worse. Here's what you should ask your team about."

This is where the LLM relevance engine becomes visible value.

## Design Principle: Board memo first. Footnotes later.

The executive layer sits **above** the progressive drill-down ‚Äî not beside it.

**Executive mental model:**
```
Portfolio narrative ‚Üí Theme ‚Üí Affected tenants/properties ‚Üí Analyst memo ‚Üí Evidence
```

**AM mental model:**
```
Tenant issue ‚Üí What changed ‚Üí What to do ‚Üí Evidence
```

Same data. Different entry point. That's elegant product design.

## What makes execs say "wow"

Not the UI. The **judgment**.

When the system says:

> "While two tenants triggered alerts this week, their risks are unrelated and isolated. No systemic deterioration detected."

That sentence alone is worth the demo. Humans think that way. Dashboards don't.

---

# 3) UX/IA: Mobile-First Information Architecture

## 3.1 Navigation (mobile thumb-friendly)

Bottom Tab Bar:

1. **Brief** ‚Äî persona-aware landing (Exec vs AM view)
2. **Properties**
3. **Alerts**
4. **Search**

Top right:

* Role switch (Demo): **Executive / Asset Manager**
* Profile menu (optional)

**Persona-based landing:**
* Executive ‚Üí lands on **Portfolio Credit Brief** (narrative + posture + delta)
* Asset Manager ‚Üí lands on **AM Credit Brief** (filtered to assigned properties, action-focused)

### Role Switch Strategy (Demo vs Production)

**For demo: Explicit role switch.**

```
üë§ Head of Assets ‚ñæ
   Switch role (demo)
```

Place in top-right profile area ‚Äî implies "who I'm logged in as." Never in main nav.

Role switching is a **demo affordance**, not a product feature.

**Verbal positioning during demo:**
> "For the demo, I can switch between executive and asset manager perspectives. In production, this would be driven entirely by role-based access."

Then move on. Don't linger.

**For production: Implicit RBAC-driven experience.**

No switch. Same components, different entry points based on role.

| Capability               | Exec | AM |
| ------------------------ | ---- | -- |
| Portfolio brief          | ‚úÖ    | ‚ùå  |
| Concentration insights   | ‚úÖ    | ‚ùå  |
| Exec questions           | ‚úÖ    | ‚ùå  |
| Property drill-down      | ‚úÖ    | ‚úÖ  |
| Tenant memo              | ‚úÖ    | ‚úÖ  |
| Evidence                 | ‚úÖ    | ‚úÖ  |
| Assigned properties only | ‚ùå    | ‚úÖ  |

**Key principle:** Execs can see down. AMs cannot see up.

## 3.2 "No noise by default" UX rules

* **Never show raw feeds** by default.
* Cap ‚ÄúBrief‚Äù to **max 7 cards**.
* Cap evidence per memo to **max 10 sources**.
* Hide ‚ÄúStable‚Äù tenants behind a toggle.
* Each screen has **one primary action** and **progressive disclosure**.

## 3.3 Screen specs (mobile)

### A) Executive Portfolio Brief ‚Äî default landing for Exec

**Goal:** Under 30 seconds to full portfolio understanding. Judgment, not data.

**Above-the-fold sections:**

#### Section 0 ‚Äî Portfolio Verdict (top-line call)

**One sentence. Above everything else.**

This answers the exec's first subconscious question: *"Is this better or worse than last time I looked?"*

Example:
> **Portfolio status:** Risk increased modestly this week, driven by two isolated tenant liquidity events. No systemic deterioration detected.

Or:
> **Portfolio status:** Stable. No material changes this week.

This single directional verdict dramatically increases executive confidence.

#### Section 1 ‚Äî "What you need to know right now"

**Maximum 5 bullets. Hard limit. Priority-ordered.**

Each bullet is a synthesized insight, not a tenant. Explicitly labeled by priority:

* üî¥ **Priority 1 ‚Äî Requires discussion**
* üü° **Priority 2 ‚Äî Monitor**
* ‚ö™ **Priority 3 ‚Äî FYI**

Examples:
> üî¥ **Retail exposure deteriorated this week due to two unrelated tenant liquidity events.**
> *Driven by Acme Retail and Northstar Apparel.*

> üü° **One office property now has >40% rent exposure to watch-list tenants.**
> *Riverside Tower.*

> ‚ö™ **No new bankruptcy risk identified this week.**

Each bullet is tappable ‚Üí expands into supporting tenants ‚Üí memo ‚Üí evidence.

Priority labeling signals judgment, confidence, and maturity ‚Äî even with only 3 bullets.

#### Section 2 ‚Äî Portfolio Risk Posture

Not charts. Not graphs. Three large cards with counts:

* üü• **3 Critical exposures**
* üü® **9 Watch-list exposures**
* üü© **18 Stable**

Tap any card ‚Üí filtered tenant/property list.

Execs want counts, not percentages.

#### Section 3 ‚Äî What changed since last week

Three rows only:

* ‚Üë **4 tenants deteriorated**
* ‚Üí **23 unchanged**
* ‚Üì **3 improved**

Tap "deteriorated" ‚Üí see which ones ‚Üí drill down.

This instantly communicates: "Is the ship drifting or stable?"

#### Section 4 ‚Äî Concentration risk (the real exec concern)

Execs lose sleep over concentration, correlation, and clusters ‚Äî not single tenants.

> **"Where risk is clustering"**

Examples:
* "Retail tenants account for 67% of all watch-list exposure."
* "Two properties contain 55% of portfolio credit risk signals."
* "Three tenants appear across five properties."

Each item expands to show: properties affected, tenants involved, short LLM-generated explanation.

#### Section 5 ‚Äî Questions to raise this week

Execs don't just consume information ‚Äî they prepare conversations. They think in questions, not actions.

**2‚Äì3 questions max.** LLM-generated from the same portfolio synthesis.

Examples:
> ‚Ä¢ "What is our contingency plan if Acme Retail seeks rent relief?"
> ‚Ä¢ "Are we comfortable with current exposure concentration at Riverside Tower?"
> ‚Ä¢ "Do we expect follow-on disclosures from Northstar Apparel?"

This makes the product feel like a senior advisor, not a reporting tool.

#### Footer ‚Äî Visible Restraint + Institutional Anchor

Execs are suspicious of monitoring tools ("this will light up constantly"). Proactively demonstrate discipline and seriousness.

Always visible at bottom of exec brief:

> **30 tenants reviewed this week. 5 required your attention.**
>
> *Prepared as of Jan 17, 2026 using all available filings and verified sources.*

This communicates:
* Coverage (we looked at everything)
* Discipline (we filtered aggressively)
* Signal-to-noise (you're only seeing what matters)
* Institutional credibility (reads like a memo header)

**Thresholds for exec page content:**
1. Must be **aggregated** (not single-entity by default)
2. Must be **interpretable in one sentence**

If it can't be summarized cleanly, it doesn't belong here.

---

### B) AM Credit Brief ‚Äî default landing for Asset Manager

**Goal:** immediate "wow": clarity + actionability for assigned properties.

**UI components**

* Header: ‚ÄúToday‚Äôs Credit Brief‚Äù
* Subheader: ‚ÄúUpdated: Jan 17, 2026 6:00am CT‚Äù (or similar)
* Filter chips: `Critical`, `Watch`, `Positive`, `All` (default = Critical+Watch+Positive)
* List of **cards** (max 7):

  * Tenant name
  * Property badge(s) (or ‚Äú3 properties‚Äù)
  * One-line ‚ÄúWhat changed‚Äù
  * Severity pill (Critical/Watch/Positive)
  * Confidence badge (High/Med)
  * Time horizon (Immediate/Near-term/Structural)

**Primary interaction**

* Tap card ‚Üí **Action Memo**

**Delight interactions**

* Long-press card ‚Üí Quick Peek (score trend + last event)
* Swipe left ‚Üí ‚ÄúAssign‚Äù (demo-only)

---

### B) Action Memo (Tenant Event Memo) ‚Äî hero screen

**Goal:** feels like a senior credit analyst wrote it.

**Structure (tight, scannable)**

* Header row:

  * Tenant + status pill
  * Watch score (0‚Äì100) + 7-day trend arrow
* Section 1: **What changed** (2‚Äì3 sentences max)
* Section 2: **Why it matters (credit)** (max 3 bullets)
* Section 3: **Recommended actions** (max 3 bullets)
* Section 4: **What to watch next** (max 2 bullets)
* CTA button: **View Evidence (N)** opens bottom sheet

**Evidence bottom sheet**

* List (3‚Äì10) sources:

  * title, publisher, date
  * ‚ÄúKey excerpt‚Äù (2‚Äì3 lines)
  * external link icon (opens new tab / in-app viewer)

**Secondary chips**

* `Why` ‚Üí expands 1‚Äì2 sentence credit mechanism
* `Exposure` ‚Üí shows ‚ÄúProperties: X | Leases: Y | Rent share: (demo)‚Äù
* `History` ‚Üí opens tenant timeline (material-only)

---

### C) Properties

**List view**

* Search bar (property name/city)
* Filter chips: `Needs attention`, `All`
* Property cards:

  * Property name, city
  * Status pill (Critical/Watch/Stable/Improving)
  * ‚ÄúIssues: 2‚Äù + ‚ÄúTenants: 9‚Äù

**Property detail**

* Section 1: ‚ÄúIssues‚Äù (cards, max 5)
* Section 2: ‚ÄúTenant roster‚Äù

  * Default shows only Critical/Watch tenants
  * Toggle: ‚ÄúShow stable tenants‚Äù
* Tap a tenant ‚Üí Tenant timeline

---

### D) Tenant Timeline (material-only)

A vertical timeline of **only** material events with:

* Date + severity
* Title
* 1 sentence summary
* Link to memo / evidence

---

### E) Alerts (Inbox)

A small queue:

* Grouped sections: `Critical`, `Watch`, `Positive`
* Each item supports:

  * Mark reviewed
  * Snooze (24h / 7d) (demo-only, stored locally)

---

### F) Search (instant)

* Typeahead results for **tenants + properties**
* Tenants show "Resolved entity" badge:

  * Public / Private / Unknown
* Tap result ‚Üí tenant or property

---

## 3.4 Screen Interaction Contracts

Navigation mechanics to prevent UI thrash during build.

### Route vs Sheet vs Inline

| Interaction | Pattern | Route |
|-------------|---------|-------|
| Brief ‚Üí Tenant Memo | Route change | `/tenant/:id/event/:eventId` |
| Memo ‚Üí Evidence | Bottom sheet | (stays on memo route) |
| Expand Priority bullet | Inline expansion | (no route change) |
| Tap "Exposure" chip | Mini modal card | (no route change) |
| Tap "Why" chip | Inline expansion | (no route change) |
| Property list ‚Üí Property detail | Route change | `/property/:id` |
| Property ‚Üí Tenant | Route change | `/tenant/:id` |
| Search result ‚Üí Entity | Route change | `/tenant/:id` or `/property/:id` |

### Preloading Strategy

| Trigger | Preload |
|---------|---------|
| Touchstart on Brief card | Memo data + first 3 evidence items |
| Touchstart on Property row | Property detail + tenant roster |
| Hover on search result | Entity summary |

### Back Behavior

* Browser back always works (route-based navigation)
* Bottom sheets dismiss on swipe down or backdrop tap
* Inline expansions collapse on tap outside or re-tap header

### Animation Timing

* Route transitions: 200ms ease-out
* Bottom sheet: 300ms spring
* Inline expand: 150ms ease-out

---

# 4) Demo Mode Strategy: "Instant & Flawless"

## 4.1 Demo data principle

Everything is **precomputed**:

* Evidence packs (curated sources)
* LLM adjudications (structured memos + scoring)
* Portfolio snapshots (today vs last week)

Runtime is simply fast retrieval + rendering.

## 4.2 Freshness illusion (honest + confidence-building)

Every page shows:

* ‚ÄúLast refreshed‚Äù timestamp
* ‚ÄúRefresh cadence‚Äù (Daily / Filing-triggered / Weekly summary)

No claim of ‚Äúreal-time web search‚Äù in-demo.

---

# 5) Data Model (Postgres + JSONB)

## 5.1 Entities

### Tenant

* `id` (uuid)
* `name_display`
* `name_legal` (nullable)
* `entity_type` enum: `public | private | unknown`
* `identifiers` jsonb: `{ ticker?, cik?, lei?, website_domain?, duns? }`
* `industry` (nullable)
* `confidence_entity_resolution` float (0‚Äì1)
* `created_at`, `updated_at`

### Property

* `id` (uuid)
* `name`
* `address_city`, `address_state`
* `asset_class` (optional)
* `created_at`, `updated_at`

### Lease / Occupancy link (simplified for demo)

* `id`
* `property_id`
* `tenant_id`
* `lease_label` (e.g., ‚ÄúSuite 400‚Äù, optional)
* `rent_share_estimate` float (nullable) *(demo can fake this)*

### EvidenceSource

Represents one source item (news/filing/press release).

* `id`
* `tenant_id`
* `source_type` enum: `sec_filing | news | press_release | court | other`
* `title`
* `publisher`
* `published_at`
* `url`
* `excerpt` text (short)
* `raw_text` text (optional, stored but not displayed)
* `dedupe_hash`
* `created_at`

### Event (material-only)

One "credit event" derived from evidence and adjudication.

* `id`
* `tenant_id`
* `event_date`
* `event_type` enum (see below)
* `sentiment` enum: `positive | negative`
* `severity` int (0‚Äì100) ‚Äî magnitude of impact, regardless of sentiment
* `confidence` float (0‚Äì1)
* `time_horizon` enum: `immediate | near_term | structural`
* `headline`
* `summary` text (1‚Äì2 lines)
* `memo` jsonb (structured memo output)
* `evidence_ids` uuid[] (references EvidenceSource)
* `created_at`

### TenantScoreSnapshot

* `id`
* `tenant_id`
* `as_of_date` (date)
* `watch_score` int (0‚Äì100)
* `delta_7d` int
* `status` enum: `critical | watch | stable | improving`
* `top_event_id` uuid (nullable)

### PropertyScoreSnapshot

* `id`
* `property_id`
* `as_of_date`
* `status` enum
* `watch_score` int
* `issues_count` int

### User (demo-simple)

* `id`
* `role` enum: `exec | am`
* `name`
* `assigned_property_ids` uuid[] (for AM)

### PortfolioBriefSnapshot (executive layer)

Precomputed weekly synthesis for the executive view.

* `id`
* `as_of_date` (date)
* `portfolio_verdict` jsonb ‚Äî single directional call: direction, magnitude, statement, confidence
* `narrative_bullets` jsonb ‚Äî max 5 synthesized insights with priority (1/2/3) and supporting entity IDs
* `risk_posture` jsonb ‚Äî `{ critical: int, watch: int, stable: int, improving: int }`
* `week_over_week` jsonb ‚Äî `{ deteriorated: int, improved: int, unchanged: int }`
* `concentration_insights` jsonb ‚Äî array of clustering observations with affected entity IDs
* `exec_questions` jsonb ‚Äî 2‚Äì3 questions for exec to raise with team
* `coverage` jsonb ‚Äî `{ tenants_reviewed: int, tenants_surfaced: int }`
* `created_at`

---

# 6) Event Types & Severity Policy

## 6.1 Event types (demo-ready)

* `bankruptcy_or_restructuring`
* `liquidity_stress`
* `covenant_or_debt_event`
* `rating_action` *(stub if not licensed; can still exist as ‚Äúreported rating action‚Äù with source)*
* `sec_material_disclosure` (8-K / risk factor change)
* `earnings_shock_or_guidance_cut`
* `operational_disruption` (closures, layoffs, supply)
* `litigation_or_regulatory`
* `mna_or_divestiture`

**Positive event types (equally weighted in relevance)**

* `rating_upgrade` (upgrade or positive outlook change)
* `debt_paydown_or_refinance` (improved capital structure)
* `earnings_beat_or_guidance_raise`
* `liquidity_improvement` (new credit facility, equity raise, asset sale proceeds)
* `expansion_or_growth` (new contracts, market expansion, hiring)
* `operational_turnaround` (margin improvement, cost reduction success)
* `litigation_resolution` (favorable settlement or dismissal)

## 6.2 Severity policy (simple + believable)

Severity = weighted combination:

* Type base weight (e.g., bankruptcy highest negative, rating upgrade highest positive)
* Credibility (source tier)
* Confirmation count (independent sources)
* Tenant importance (exposure proxy)

**Positive events use the same rigor:**

* Positive severity score (0‚Äì100) measures magnitude of improvement
* Must meet same evidence thresholds as negative events
* No "hopium"‚Äîonly confirmed, material improvements surface

Then **tenant watch score** is a smoothed value over time:

* Sticky, non-twitchy
* Big events move it (up or down), small events barely nudge
* Positive events can move a tenant from Watch ‚Üí Stable or improve confidence

### 6.2.1 Scoring Thresholds (concrete numbers)

**Status classification:**

| Status | Severity | Confidence | Additional |
|--------|----------|------------|------------|
| Critical | ‚â• 80 | ‚â• 0.75 | ‚Äî |
| Watch | ‚â• 55 | ‚â• 0.60 | ‚Äî |
| Improving | ‚â• 55 | ‚â• 0.60 | sentiment = positive |
| Stable | < 55 | any | or no material events |

**Corroboration override:**
* If ‚â•2 independent Tier 1/2 sources within 72 hours ‚Üí allow Watch even if confidence slightly lower (‚â• 0.50)

**Sticky score rules:**
* `watch_score` only updates on new validated events
* Score decay: if no new events for 30 days, score drifts toward 50 (neutral)
* Maximum single-event movement: ¬±25 points

**UI caps (hard limits):**

| Element | Max |
|---------|-----|
| Executive narrative bullets | 5 |
| Brief cards (AM view) | 7 |
| Evidence items per memo | 10 |
| Concentration insights | 4 |
| Exec questions | 3 |

---

# 7) LLM Adjudication: Schemas & Prompts (Precomputed)

## 7.1 Evidence Pack (input to LLM)

We feed Gemini 3 Pro a tight bundle (max 10 evidence items), already deduped, with the tenant entity card.

### Example `EvidencePack` (stored JSON)

```json
{
  "tenant": {
    "id": "uuid",
    "name_display": "Acme Retail",
    "entity_type": "public",
    "identifiers": { "ticker": "ACME", "cik": "0000123456" },
    "industry": "Retail"
  },
  "as_of": "2026-01-17T12:00:00Z",
  "evidence": [
    {
      "evidence_id": "uuid",
      "source_type": "sec_filing",
      "title": "8-K: Amendment to Credit Agreement",
      "publisher": "SEC EDGAR",
      "published_at": "2026-01-16T21:10:00Z",
      "url": "https://...",
      "excerpt": "Company disclosed covenant relief and increased pricing..."
    }
  ]
}
```

## 7.2 Required LLM Output Schema (strict)

This output is what drives the UI + scoring.

```json
{
  "tenant_id": "uuid",
  "material_event": true,
  "event_type": "covenant_or_debt_event",
  "sentiment": "negative",  // "negative" | "positive"
  "severity": 86,  // 0-100, magnitude of impact (applies to both positive and negative)
  "confidence": 0.87,
  "time_horizon": "near_term",
  "headline": "Covenant relief and pricing increase signals tightening liquidity",
  "what_changed": "2-3 sentences max.",
  "why_it_matters": ["bullet1", "bullet2", "bullet3"],
  "recommended_actions": ["bullet1", "bullet2", "bullet3"],
  "what_to_watch_next": ["bullet1", "bullet2"],

  "citations": [
    {
      "claim": "Covenant relief was obtained and pricing increased.",
      "evidence_id": "uuid",
      "quote_spans": [
        { "field": "excerpt", "start": 34, "end": 96 }
      ],
      "quote_text": "‚Ä¶covenant relief‚Ä¶ increased pricing‚Ä¶"
    }
  ],

  "evidence_classifications": [
    {
      "evidence_id": "uuid",
      "source_tier": 1,  // 1 = SEC/PR, 2 = major news, 3 = other
      "material": true,
      "reason": "1 sentence",
      "signals": ["covenant_relief", "pricing_increase"]
    }
  ],

  "unknowns": [
    "No bond maturity schedule present in evidence; cannot assess refinancing wall."
  ]
}
```

**Citation requirements:**
* Every sentence in `what_changed` must have ‚â•1 citation
* Every bullet in `why_it_matters` must have ‚â•1 citation
* `quote_text` must exist verbatim in the referenced evidence
* `quote_spans` must align with stored text

**Unknowns:** Model must explicitly report what it cannot determine from provided evidence.

## 7.3 Prompting strategy (so it behaves like a credit analyst)

* System: "You are a senior credit analyst for CRE tenancy risk. You must be conservative. No speculation. You may only use the evidence items provided. Every material claim must cite evidence_id with exact quote_text. If information is missing, add to unknowns array."
* Hard constraints:

  * Max bullets
  * Max sentence lengths
  * Must output valid JSON
  * Every claim requires quote-anchored citation
  * If weak evidence ‚Üí `material_event=false` + short explanation
  * If cannot cite ‚Üí must go in `unknowns`, not in memo text

## 7.4 Executive Portfolio Brief Schema (portfolio-level adjudication)

Once per snapshot (e.g., weekly), run a **portfolio-level synthesis** to generate the executive view.

### Input

* All material tenant events from the period
* Property/tenant relationships
* Prior snapshot for delta computation

### Output (strict schema)

```json
{
  "as_of": "2026-01-17",

  "portfolio_verdict": {
    "direction": "increased",  // "increased" | "decreased" | "stable"
    "magnitude": "modestly",   // "significantly" | "modestly" | null
    "statement": "Risk increased modestly this week, driven by two isolated tenant liquidity events. No systemic deterioration detected.",
    "confidence": 0.88
  },

  "narrative_bullets": [
    {
      "statement": "Retail exposure deteriorated this week due to two unrelated tenant liquidity events.",
      "priority": 1,  // 1 = requires discussion, 2 = monitor, 3 = FYI
      "confidence": 0.91,
      "supporting_tenant_ids": ["uuid1", "uuid2"],
      "supporting_property_ids": ["uuid3"]
    },
    {
      "statement": "One office property now has >40% rent exposure to watch-list tenants.",
      "priority": 2,
      "confidence": 0.87,
      "supporting_tenant_ids": ["uuid4"],
      "supporting_property_ids": ["uuid5"]
    },
    {
      "statement": "No new bankruptcy risk identified this week.",
      "priority": 3,
      "confidence": 0.95,
      "supporting_tenant_ids": [],
      "supporting_property_ids": []
    }
  ],

  "risk_posture": {
    "critical": 3,
    "watch": 9,
    "stable": 18,
    "improving": 4
  },

  "week_over_week": {
    "deteriorated": 4,
    "improved": 3,
    "unchanged": 23
  },

  "concentration_insights": [
    {
      "statement": "Two properties contain 55% of portfolio credit risk signals.",
      "property_ids": ["uuid1", "uuid2"],
      "tenant_ids": ["uuid3", "uuid4", "uuid5"]
    },
    {
      "statement": "Retail tenants account for 67% of all watch-list exposure.",
      "property_ids": [],
      "tenant_ids": ["uuid1", "uuid2", "uuid3"],
      "segment": "retail"
    }
  ],

  "exec_questions": [
    "What is our contingency plan if Acme Retail seeks rent relief?",
    "Are we comfortable with current exposure concentration at Riverside Tower?",
    "Do we expect follow-on disclosures from Northstar Apparel?"
  ],

  "coverage": {
    "tenants_reviewed": 30,
    "tenants_surfaced": 5
  },

  "prepared_statement": "Prepared as of Jan 17, 2026 using all available filings and verified sources."
}
```

### Prompting for portfolio synthesis

* System: "You are a senior credit portfolio analyst preparing a weekly brief for the Head of Assets. Synthesize individual tenant events into portfolio-level insights. Be conservative. Start with a single-sentence directional verdict. Prioritize bullets by urgency. Generate 2‚Äì3 questions the exec should raise with their team. Focus on systemic patterns, concentration risk, and week-over-week changes."
* Hard constraints:
  * Must include portfolio_verdict with directional call
  * Max 5 narrative bullets, each with priority (1/2/3)
  * Max 4 concentration insights
  * Max 3 exec_questions
  * Every statement must reference supporting entity IDs
  * If no systemic pattern exists, say so explicitly (e.g., "risks are unrelated and isolated")
  * Include coverage stats (tenants reviewed vs surfaced)

## 7.5 Evidence Grounding & Hallucination Prevention

**Golden rule:** The model must only talk about evidence we provide, and every claim must be provably traceable to that evidence.

### 7.5.1 Closed-world evidence

For each tenant run, the LLM receives:
* A tenant entity card
* An Evidence Pack (3‚Äì10 items)
* Nothing else

System instruction (non-negotiable):
* "You may only use the evidence items provided."
* "If it isn't in the evidence pack, you must say `unknown`."
* "Every material claim must cite `evidence_id`."
* "If you cannot cite, set `material_event=false`."

The model must also report gaps:
```json
"unknowns": [
  "No bond maturity schedule present in evidence; cannot assess refinancing wall.",
  "No rating agency action included; cannot confirm downgrade."
]
```

### 7.5.2 Machine-verifiable citations (not just URLs)

Weak citation: a URL in text.
Strong citation: claims mapped to evidence_id with verified quote spans.

**Required citation structure:**

```json
{
  "claim": "Covenant relief was obtained and pricing increased.",
  "evidence_id": "uuid",
  "quote_spans": [
    { "field": "excerpt", "start": 34, "end": 96 }
  ],
  "quote_text": "‚Ä¶covenant relief‚Ä¶ increased pricing‚Ä¶"
}
```

The model must "point" into text we already have. Then we programmatically verify:
* `quote_text` exists verbatim inside `EvidenceSource.excerpt` or `raw_text`
* `start`/`end` align
* `evidence_id` exists and belongs to that tenant

If verification fails ‚Üí memo rejected, never appears.

### 7.5.3 Deterministic validation pipeline

Nothing reaches UI without passing checks:

1. Build evidence pack
2. LLM generates JSON
3. **Validator runs (deterministic)**
4. If pass ‚Üí save Event + Memo
5. If fail ‚Üí drop + log

**Validator checks (must-haves):**

| Check | Rule |
|-------|------|
| Schema validity | Strict JSON schema compliance |
| Evidence ID integrity | Each cited `evidence_id` exists and belongs to same tenant |
| Quote verification | `quote_text` is substring of stored text, or spans align |
| Claim coverage | Every sentence in `what_changed` has ‚â•1 citation |
| Bullet coverage | Every bullet in `why_it_matters` has ‚â•1 citation |
| No uncited named entities | Numbers, dates, dollar amounts, lender names must be cited |
| Source type rules | `sec_material_disclosure` requires ‚â•1 `sec_filing` source |

**Hard reject on any failure.**

### 7.5.4 Two-model pattern: extract first, reason second

Reduces hallucinations significantly by separating fact extraction from judgment.

**Step A ‚Äî Evidence extraction (cheap model or rules)**

For each evidence item, extract factual statements with quotes:

```json
{
  "evidence_id": "uuid",
  "facts": [
    {
      "fact": "Company amended credit agreement to obtain covenant relief.",
      "quote_text": "‚Ä¶amended the Credit Agreement‚Ä¶ covenant relief‚Ä¶",
      "source_field": "raw_text"
    }
  ]
}
```

**Step B ‚Äî Adjudication (Gemini 3 Pro)**

Judge model receives:
* Tenant card
* Extracted facts (each already anchored by quotes)

The judge operates on a clean fact table ‚Äî no temptation to invent details.

### 7.5.5 Source tier policy

Define source credibility tiers:

| Tier | Sources |
|------|---------|
| Tier 1 | SEC filings (EDGAR), company press releases |
| Tier 2 | Reuters, WSJ, FT, Bloomberg (licensed) |
| Tier 3 | Everything else |

**Enforcement rules:**
* Critical events require ‚â•1 Tier 1 or Tier 2 source
* Tier 3-only evidence can never generate "Critical" severity
* Source tier displayed in UI for transparency

### 7.5.6 Entity resolution confidence gating

Prevent attaching wrong news to wrong tenant (e.g., wrong "Acme").

* If entity resolution confidence < threshold:
  * Do not auto-attach
  * Require manual confirm flag OR exclude from surfaced items

For demo: curate dataset to avoid ambiguity.
For production: confidence gate is mandatory.

### 7.5.7 UI "show your work" pattern

Trust improves when provenance is obvious:

* Every memo shows: "Based on: 1 filing, 2 reputable news sources"
* Evidence button shows cited sources first (not all sources)
* Quote highlights in evidence viewer

Citations become a product feature, not just an audit trail.

---

## 7.6 Precompute workflow

* For each tenant in demo universe:

  1. Build evidence pack
  2. **Extract facts with quotes** (Step A)
  3. **Run adjudication on fact table** (Step B)
  4. **Validate against all checks** (7.5.3)
  5. If pass: create `Event` + store memo
  6. If fail: log rejection reason, do not surface
  7. Compute tenant score snapshots

* For portfolio (once per snapshot):

  8. Aggregate all material events
  9. Run portfolio-level synthesis
  10. Validate executive brief schema
  11. Store `PortfolioBriefSnapshot`

*(The demo app never calls the model. All validation happens at precompute time.)*

---

# 8) Backend API (Fast + Cacheable)

Base URL: `/api/v1`

## 8.1 Auth (demo)

* Simple ‚Äúrole token‚Äù query param or header:

  * `X-DEMO-ROLE: hoa|am`
  * `X-DEMO-USER: jane`

## 8.2 Endpoints

### Executive Portfolio Brief

* `GET /exec/brief?asOf=2026-01-17`
  Returns the full executive view: verdict, narrative, posture, delta, concentration, questions, coverage.

Response:

```json
{
  "as_of": "2026-01-17",
  "updated_at": "2026-01-17T12:00:00Z",

  "portfolio_verdict": {
    "direction": "increased",
    "magnitude": "modestly",
    "statement": "Risk increased modestly this week, driven by two isolated tenant liquidity events. No systemic deterioration detected."
  },

  "narrative_bullets": [
    {
      "statement": "Retail exposure deteriorated this week due to two tenant liquidity events.",
      "priority": 1,
      "confidence": 0.91,
      "supporting_tenants": [
        { "tenant_id": "uuid", "tenant_name": "Acme Retail" }
      ],
      "supporting_properties": [
        { "property_id": "uuid", "property_name": "Park Plaza" }
      ]
    }
  ],

  "risk_posture": {
    "critical": 3,
    "watch": 9,
    "stable": 18,
    "improving": 4
  },

  "week_over_week": {
    "deteriorated": [
      { "tenant_id": "uuid", "tenant_name": "Acme Retail", "from_status": "watch", "to_status": "critical" }
    ],
    "improved": [],
    "unchanged_count": 23
  },

  "concentration_insights": [
    {
      "statement": "Two properties contain 55% of portfolio credit risk signals.",
      "properties": [
        { "property_id": "uuid", "property_name": "Riverside Tower" }
      ],
      "tenants": []
    }
  ],

  "exec_questions": [
    "What is our contingency plan if Acme Retail seeks rent relief?",
    "Are we comfortable with current exposure concentration at Riverside Tower?"
  ],

  "coverage": {
    "tenants_reviewed": 30,
    "tenants_surfaced": 5,
    "prepared_statement": "Prepared as of Jan 17, 2026 using all available filings and verified sources."
  }
}
```

### AM Brief

* `GET /am/brief?asOf=2026-01-17`
  Returns top 3‚Äì7 actionable items for assigned properties.

Response:

```json
{
  "as_of": "2026-01-17",
  "updated_at": "2026-01-17T12:00:00Z",
  "items": [
    {
      "tenant_id": "uuid",
      "tenant_name": "Acme Retail",
      "property_badges": ["Park Plaza", "Riverside Mall"],
      "status": "critical",
      "severity": 86,
      "confidence": "high",
      "time_horizon": "near_term",
      "one_liner": "Covenant relief and higher borrowing costs disclosed in 8-K."
    }
  ]
}
```

### Memo

* `GET /tenants/:tenantId/memo?eventId=:eventId`

### Tenant timeline

* `GET /tenants/:tenantId/timeline`

### Evidence list

* `GET /events/:eventId/evidence`

### Properties list

* `GET /properties`
* `GET /properties/:propertyId`

### Alerts inbox

* `GET /alerts`
* `POST /alerts/:alertId/reviewed`
* `POST /alerts/:alertId/snooze` (stores local/demo)

### Search

* `GET /search?q=acme`

## 8.3 Performance

* All endpoints cacheable with ETag
* CDN caching for evidence excerpts
* Prefetch memo + evidence on touchstart

---

# 9) Frontend Implementation (Mobile-first)

## 9.1 Tech

* Next.js (or Remix) + React
* Tailwind
* Component library: shadcn/ui (fast, clean)
* Route-level data loading + prefetch
* Skeleton loaders (but target near-zero visible loading)

## 9.2 Responsive rules

* Mobile-first CSS; desktop is progressive enhancement
* Avoid tables; use stacked cards
* Bottom sheets for evidence
* Tap targets ‚â• 44px

## 9.3 Micro-interactions (wow moments)

* Card tap animates into memo (shared element transition)
* Evidence sheet slides up with snap points
* ‚ÄúWhy‚Äù chip expands inline (no navigation)
* ‚ÄúExposure‚Äù chip shows tiny modal card

---

# 10) Demo Dataset: What to Build

## 10.1 Size

* **10 properties**
* **30 tenants**
* **~15 material events** across two snapshots (today vs last week)

## 10.2 Composition

**By entity type:**

* ~15 public tenants:
  * Negative examples: 8-K debt/covenant, 10-Q liquidity language, earnings shock
  * Positive examples: earnings beat, debt refinance at better terms, rating upgrade
* ~15 private tenants:
  * Negative examples: closures/layoffs/litigation
  * Positive examples: expansion announcements, new funding rounds, acquisition by stronger parent

**By status (orthogonal to entity type):**

* ~18 stable (no material news) ‚Äî intentionally quiet to prove "no noise"
* ~8 watch/critical (negative events)
* ~4 improving (positive events)

## 10.3 Scripted storylines (so clicks always wow)

* 2‚Äì3 critical "red" events (deteriorating credit)
* 5‚Äì6 watch "yellow" events
* 3‚Äì4 positive "green" events (improving credit)
* ~18 stable (no material news)

Each material event (positive or negative) has:
* Memo with analyst-quality narrative
* Evidence pack with 3‚Äì6 items
* A clear "next step" action list (even positive events have actions, e.g., "consider lease extension opportunity")

---

# 11) Railway Deployment

## 11.1 Services

* Web (Next.js)
* API (Node/Express or FastAPI)
* Postgres
* Redis (optional; can rely on CDN + in-memory for demo)

## 11.2 Demo configuration

* Seed script loads dataset + snapshots
* Environment variable `DEMO_ASOF_DATE=2026-01-17`
* Option to switch to ‚Äúlast week‚Äù snapshot via UI toggle

---

# 12) QA & Acceptance Criteria (Demo Readiness)

## 12.1 UX acceptance

* Opening link on iPhone loads Brief and is usable immediately
* Every tap yields a meaningful next step:

  * Brief ‚Üí Memo ‚Üí Evidence
* No empty states in demo flow (always something to show)

## 12.2 Noise acceptance

* Brief never exceeds 7 items
* Tenant timeline shows only material events
* Evidence never exceeds 10 sources and is deduped

## 12.3 Credibility acceptance

* Every memo claim maps to a citation (evidence_id + URL)
* Timestamps and ‚Äúrefresh cadence‚Äù visible
* Conservative language (no speculation)

## 12.4 Performance acceptance (perceived)

* Time-to-first-content under ~1 second on typical mobile
* Tap transitions feel immediate (prefetch + cached JSON)

---

# 13) Demo Script: Executive-First Flow

The demo has two acts: **Executive (telescope)** first, then **Asset Manager (microscope)**.

---

## Act 1: Executive Demo (first 2 minutes)

**Goal:** Judgment, synthesis, and restraint ‚Äî in under 30 seconds to understanding.

### Step 1 ‚Äî Open link on phone

Lands on **Portfolio Credit Brief** (not a dashboard, not a table).

**First thing exec sees ‚Äî the verdict (top-line call):**
> **Portfolio status:** Risk increased modestly this week, driven by two isolated tenant liquidity events. No systemic deterioration detected.

This answers the exec's first subconscious question before they even scroll.

**Below that:**
* üî¥/üü°/‚ö™ Priority-labeled narrative bullets (not equal weight ‚Äî explicit ranking)
* Risk posture cards (3 critical / 9 watch / 18 stable)
* Week-over-week delta (4 deteriorated / 3 improved)

**At the bottom ‚Äî the restraint indicator:**
> "30 tenants reviewed. 5 required your attention."

**Within 10 seconds**, exec already understands:
* Better or worse than last week? (verdict)
* What to focus on first? (priorities)
* Is this noisy? (coverage stat says no)

### Step 2 ‚Äî Tap a Priority 1 bullet

> üî¥ "Retail exposure deteriorated this week due to two unrelated tenant liquidity events."

Expands to show:
* 2 tenants (Acme Retail, Northstar Apparel)
* 3 affected properties
* One-sentence explanation

### Step 3 ‚Äî Tap one tenant ‚Üí Action Memo

Full analyst-quality memo:
* What changed
* Why it matters (credit)
* Recommended actions
* What to watch next

Evidence available but optional ‚Äî exec doesn't need to click.

### Step 4 ‚Äî Back ‚Üí Scroll to "Questions to raise this week"

> ‚Ä¢ "What is our contingency plan if Acme Retail seeks rent relief?"
> ‚Ä¢ "Are we comfortable with current exposure concentration at Riverside Tower?"

**This is the moment.** The product just told the exec what to ask in their next meeting.

It feels like a senior advisor, not a reporting tool.

### Step 5 ‚Äî Tap "Concentration risk"

> "Two properties contain 55% of portfolio credit risk signals."

Shows which properties, which tenants, why.

**At this point, you've demonstrated:**
* ‚úÖ Directional verdict (better/worse)
* ‚úÖ Explicit prioritization (what matters most)
* ‚úÖ Conversation guidance (what to ask)
* ‚úÖ Visible restraint (30 reviewed, 5 surfaced)
* ‚úÖ Judgment + synthesis + auditability

That's executive magic.

---

## Act 2: Asset Manager Demo (next 2‚Äì3 minutes)

**Goal:** Show it's operational, not just a briefing tool.

### Step 5 ‚Äî Switch role ‚Üí Asset Manager

Brief now filters to assigned properties only.

Sees:
* "You have 2 items requiring attention"
* Action-focused cards (not narrative)

### Step 6 ‚Äî Tap top item ‚Üí Memo ‚Üí Evidence

Full drill-down:
* Memo with actions
* Evidence bottom sheet with citations
* External links to source documents

### Step 7 ‚Äî Tap a positive (green) item

Shows improvement memo:
* What got better
* Opportunity actions (e.g., "consider lease extension")

### Step 8 ‚Äî Properties ‚Üí pick a property ‚Üí Issues list

Shows property-level view with tenant roster.

### Step 9 ‚Äî Search a tenant

Instant typeahead, resolved entity badge, status indicator.

---

## What the exec walks away thinking

* "It told me better or worse in one sentence."
* "It told me what to focus on first."
* "It told me what to ask my team."
* "It didn't light up with noise ‚Äî 30 reviewed, 5 surfaced."
* "This is how we should run portfolio oversight."
* "I can drill down when I want ‚Äî but I don't have to."

---

## Why this completes the product

| Before | Now |
|--------|-----|
| ‚úÖ Excellent analysis | ‚úÖ Top-line verdict |
| ‚úÖ Great drill-down | ‚úÖ Priority ordering |
| ‚ùå No narrative layer | ‚úÖ Conversation guidance |
| ‚ùå No exec psychology | ‚úÖ Visible restraint |
| | ‚úÖ Narrative + synthesis |
| | ‚úÖ Drill-down + audit trail |

This is the difference between:
> "Nice tool"

and
> "This is how we should run portfolio oversight."

---

If you want the fastest path to build: next I can output (1) **exact page-by-page component checklist** for the frontend, (2) a **database schema migration**, (3) the **seed dataset format** (CSV/JSON), and (4) the exact **LLM adjudication prompt + JSON Schema** you validate against.
